# LLM-Evaluation-Prompt-Optimization-Playground
A human-in-the-loop LLM evaluation system that turns model outputs into measurable experiments, enabling data-driven optimization of prompts and models.
